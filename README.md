# Intelligent-Customer-query-Categorization-Engine

## Overview
Customer support teams in banking often receive thousands of queries daily, ranging from loan issues to account problems. Manually categorizing these queries is time-consuming and can lead to inefficiencies in ticket routing.

This project provides a complete end-to-end solution to automatically categorize customer banking queries using Natural Language Processing (NLP) and Machine Learning. The system is designed to help banks and financial institutions improve operational efficiency, reduce response time, and streamline support processes.

The project goes beyond a simple classifierâ€”it covers everything from raw data processing to production deployment. It includes:

Collecting and cleaning real-world banking query data

Performing feature engineering and building a scalable ML pipeline

Comparing classical NLP models (TF-IDF + Logistic Regression) with BERT

Fine-tuning BERT for 50 epochs to achieve high accuracy

Deploying the model using FastAPI (backend) and Swagger (API testing)

Building a Streamlit frontend dashboard for easy interaction

Adding analytics and visualizations for non-technical stakeholders

Dockerizing the entire solution for seamless deployment with one command

This ensures that both technical and non-technical users can benefit from an intelligent, production-ready query categorization engine.

## ğŸš€ Features
ğŸ”¹ Data Engineering â€“ Cleaned and processed raw banking query data

ğŸ”¹ ML Pipeline â€“ TF-IDF + Logistic Regression baseline model

ğŸ”¹ BERT Training â€“ Fine-tuned for best performance

ğŸ”¹ REST API Service â€“ Built with FastAPI, tested with Swagger UI

ğŸ”¹ Streamlit Dashboard â€“ Simple, user-friendly interface for predictions

ğŸ”¹ Analytics Tab â€“ Visual insights into ticket distribution and trends

ğŸ”¹ Dockerized Deployment â€“ Launch backend and frontend with one command

## ğŸ”‘ Data Workflow
1ï¸âƒ£ Collect Data â†’ Raw banking query CSVs
2ï¸âƒ£ Data Cleaning â†’ Remove duplicates, handle missing data, normalize text
3ï¸âƒ£ Feature Engineering â†’ Tokenization, TF-IDF vectorization
4ï¸âƒ£ Train/Test Split â†’ Stratified splitting
5ï¸âƒ£ Modeling â†’

### Logistic Regression with TF-IDF

Fine-tuned BERT
6ï¸âƒ£ Evaluation â†’ Accuracy, F1-score, confusion matrix
7ï¸âƒ£ Deployment â†’ Selected BERT for serving predictions

âš¡ Model Serving
FastAPI Backend serves the trained BERT model

Endpoint â†’ /predict for query classification

Swagger UI available for interactive API testing

## ğŸ¨ Frontend Dashboard
Built with Streamlit

### Prediction Tab:

Enter a banking query â†’ Model predicts issue category with confidence

### Analytics Tab:

Displays ticket category distribution

Shows prediction trends per hour

Visualizes confidence levels for better decision-making

Includes a Gauge Score chart to easily understand prediction confidence in a visual meter format



## ğŸ³ Dockerized Deployment
Run both backend and frontend together using Docker Compose:

docker-compose up --build
Backend API: http://localhost:8000

Frontend UI: http://localhost:8501

## ğŸ§  Skills Demonstrated
âœ… Data cleaning and preprocessing

âœ… Feature engineering for NLP

âœ… ML pipeline design and training

âœ… Model comparison (TF-IDF vs. BERT)

âœ… Docker containerization

âœ… API development with FastAPI and Swagger

âœ… Interactive frontend with Streamlit

âœ… Analytics visualization for non-technical users

âœ… Production-ready deployment

## âš™ï¸ How to Run Locally
1ï¸âƒ£ Clone the repository:

git clone https://github.com/yourusername/tickets-classifier.git
cd tickets-classifier
2ï¸âƒ£ Build and run the containers:

docker-compose up --build
3ï¸âƒ£ Access:

Backend API: http://localhost:8000/docs

Frontend UI: http://localhost:8501

# ğŸ“œ License

MIT License Â© 2025 Warda Iftikhar



